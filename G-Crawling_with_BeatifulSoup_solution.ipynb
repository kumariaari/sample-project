{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Define the function which will scrape data about a person and return it \n",
    "def get_person_data(url):\n",
    "    an_actor = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "    info = an_actor.find('table', attrs={'id': 'name-overview-widget-layout'})\n",
    "    res = {}\n",
    "    image = info.find('div', 'image').find('img')\n",
    "    if image is not None:\n",
    "        res['image_url'] = image['src']\n",
    "    else: \n",
    "        res['image_url'] = ''\n",
    "    birth_data = info.find('div', attrs={'id': 'name-born-info'})\n",
    "    if birth_data is not None:\n",
    "        res['born'] = birth_data.find('time')['datetime']\n",
    "        birth_place = birth_data.findAll('a')[-1].contents[0]\n",
    "        birth_place = birth_data.findAll('a')[-1].contents[0].split(',')\n",
    "        res['country'] = birth_place[-1]\n",
    "        res['city'] = birth_place[0]\n",
    "    else:\n",
    "        res['born'] = res['country'] = res['city'] = ''    \n",
    "    try:\n",
    "        death_data = info.find('div', attrs={'id': 'name-death-info'})\n",
    "        res['died'] = death_data.find('time')['datetime']\n",
    "    except:\n",
    "        res['died'] = ''\n",
    "    return res\n",
    "\n",
    "\n",
    "def crawl_page(startswith):\n",
    "    url = \"http://www.imdb.com/search/title?sort=num_votes,desc&start={}&title_type=feature&year=1900,2015\".format(startswith)\n",
    "    r = requests.get(url)\n",
    "    data = []\n",
    "    bs = BeautifulSoup(r.text, 'html.parser')\n",
    "    for num, movie in enumerate(bs.findAll('td','title')):\n",
    "        if (num + 1) % 10 == 0 and num > 0:\n",
    "            print num + 1\n",
    "            \n",
    "        genres = movie.find('span','genre').findAll('a')\n",
    "        \n",
    "        dirs, acts = str(movie.find('span','credit')).split(\"With:\")\n",
    "        dirs = BeautifulSoup(dirs + '</span>')\n",
    "        acts = BeautifulSoup('<span>' + acts)\n",
    "\n",
    "        directors = []\n",
    "        for i in dirs.findAll('a'):\n",
    "            directors.append(get_person_data('http://www.imdb.com' + i['href']))\n",
    "\n",
    "        actors = []\n",
    "        for i in acts.findAll('a'):\n",
    "            actors.append(get_person_data('http://www.imdb.com' + i['href']))\n",
    "\n",
    "        # Let's collect each movie data into a dictionary\n",
    "        data.append({\n",
    "            'title': movie.find('a').contents[0],\n",
    "            'genres': [g.contents[0] for g in genres],\n",
    "            'runtime': movie.find('span','runtime').contents[0].split()[0],\n",
    "            'rating': movie.find('span','value').contents[0],\n",
    "            'released': movie.find('span','year_type').contents[0][1:-1],\n",
    "            'description':  movie.find('span', 'outline').contents[0],\n",
    "            'directors': directors,\n",
    "            'actors': actors,\n",
    "        })\n",
    "    return data\n",
    "\n",
    "def collect_data(start_page, end_page):\n",
    "    data = []\n",
    "    start = time.time()\n",
    "    for i, j in enumerate(range(start_page, end_page, 50)):\n",
    "        diff = time.time() - start\n",
    "        print '\\nPage', i+1, \"{} min {} sec\".format(int(diff // 60), int(diff % 60))\n",
    "        data.extend(crawl_page(i))\n",
    "    return data\n",
    "\n",
    "#print \"\\nData about {} movies were collected\".format(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collect_data(1, 1501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('imdb_movies_1500.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
